{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo VGG16 Preentrenado para Clasificación de Imágenes\n",
        "\n",
        "## Introducción\n",
        "En esta lección, aprenderemos a usar el modelo VGG16 preentrenado para la tarea de clasificación de imágenes. VGG16 es una arquitectura profunda de red neuronal que demostró ser efectiva para reconocer imágenes.\n",
        "\n",
        "## Objetivo\n",
        "El objetivo de este cuaderno es construir un modelo de clasificación de imágenes que clasifique imágenes de gatos y perros utilizando transfer learning."
      ],
      "metadata": {
        "id": "qSS4libcdmeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX41ukAOP_qx"
      },
      "outputs": [],
      "source": [
        "# Importamos TensorFlow, la principal biblioteca para Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG16 # Para cargar el modelo VGG16\n",
        "from tensorflow.keras.preprocessing import image # Para cargar imágenes\n",
        "from tensorflow.keras.models import Model # Para construir nuestro nuevo modelo\n",
        "from tensorflow.keras.layers import Dense, Flatten # Para añadir capas a nuestro modelo\n",
        "import numpy as np # Para manipular arreglos de números\n",
        "import matplotlib.pyplot as plt # Para mostrar imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga del Modelo VGG16\n"
      ],
      "metadata": {
        "id": "gkiNEo7ld2LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo VGG16 preentrenado en el conjunto de datos ImageNet.\n",
        "# 'weights=\"imagenet\"': Usa los pesos entrenados en ImageNet.\n",
        "# 'include_top=False': Quitamos la capa final de clasificación para que podamos añadir la nuestra.\n",
        "# 'input_shape=(224, 224, 3)': Le decimos al modelo el tamaño de las imágenes que va a esperar (altura, anchura, canales de color RGB).\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Opcional: Mostramos un resumen del modelo para ver sus capas (no es necesario entenderlo todo)\n",
        "# base_model.summary()\n",
        "print(\"Modelo VGG16 cargado exitosamente. Es la 'base de conocimiento' de nuestro experto.\")"
      ],
      "metadata": {
        "id": "Du1zWAqmQF-l",
        "outputId": "6ed3aef1-0245-425f-e8fa-712c30b1ccc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo VGG16 cargado exitosamente. Es la 'base de conocimiento' de nuestro experto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparación del Modelo\n"
      ],
      "metadata": {
        "id": "6xBoXLRmeB1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Congelamos las capas del modelo base para que no se reentrenen.\n",
        "# Así, solo ajustaremos las nuevas capas que añadiremos.\n",
        "base_model.trainable = False\n",
        "print(\"Capas del modelo base congeladas. ¡Listo para añadir nuestra parte específica!\")"
      ],
      "metadata": {
        "id": "fDypDD_lQThh",
        "outputId": "8aa52e23-6173-48a0-e1c1-b55d00cce086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capas del modelo base congeladas. ¡Listo para añadir nuestra parte específica!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una nueva capa que 'aplanará' la salida del modelo base.\n",
        "# Esto es como tomar toda la información visual del experto y convertirla en una lista de números.\n",
        "x = Flatten()(base_model.output)\n",
        "\n",
        "# Añadimos una capa densa (o completamente conectada) con activación 'relu'.\n",
        "# Esta capa aprenderá patrones complejos de la información aplanada.\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "# Añadimos la capa final de salida.\n",
        "# Si tenemos 2 clases (ej. perro/gato), usaremos 'Dense(2)' y activación 'sigmoid' (para clasificación binaria).\n",
        "# Si tuviéramos N clases (ej. perro, gato, pájaro, caballo), usaríamos 'Dense(N)' y activación 'softmax'.\n",
        "output = Dense(2, activation='sigmoid')(x) # Asumiendo 2 clases: Perro y Gato\n",
        "\n",
        "# Creamos el modelo final, combinando el modelo base y nuestras nuevas capas.\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "print(\"Nuevas capas añadidas. ¡Nuestro experto ya tiene una nueva 'cabeza' para nuestra tarea!\")\n",
        "# model.summary() # Puedes descomentar para ver el resumen del modelo completo"
      ],
      "metadata": {
        "id": "woaS-HrvQXBA",
        "outputId": "5ebf45d4-f058-47f1-876b-8be9782b1ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuevas capas añadidas. ¡Nuestro experto ya tiene una nueva 'cabeza' para nuestra tarea!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparación del Dataset"
      ],
      "metadata": {
        "id": "DTcBO2LVRlHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Crea las carpetas para el dataset\n",
        "os.makedirs('data/train/cats', exist_ok=True)\n",
        "os.makedirs('data/train/dogs', exist_ok=True)\n",
        "print(\"Carpetas 'data/train/cats' y 'data/train/dogs' creadas.\")"
      ],
      "metadata": {
        "id": "WE0dduxPRlmt",
        "outputId": "aac101b3-9c8b-49d6-e957-60ca5fb8c09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carpetas 'data/train/cats' y 'data/train/dogs' creadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el tamaño de las imágenes que VGG16 espera\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32 # Número de imágenes que procesaremos a la vez (puedes probar con 4 o 8 si tu dataset es muy pequeño)\n",
        "\n",
        "# Cargamos las imágenes desde nuestras carpetas.\n",
        "# 'labels=\"inferred\"' significa que Keras deduce las etiquetas de los nombres de las carpetas.\n",
        "# 'image_size' redimensiona las imágenes.\n",
        "# 'batch_size' para procesar en grupos.\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    './data/train',\n",
        "    labels='inferred',\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"Dataset de entrenamiento cargado. Clases encontradas: {train_ds.class_names}\")\n",
        "\n",
        "# Opcional: Visualiza algunas imágenes del dataset para verificar\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for images, labels in train_ds.take(1):\n",
        "#     for i in range(min(9, len(images))): # Muestra hasta 9 imágenes\n",
        "#         ax = plt.subplot(3, 3, i + 1)\n",
        "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "#         plt.title(train_ds.class_names[labels[i]])\n",
        "#         plt.axis(\"off\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "vUem9G7gRmng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Compilación y Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "8JO3xr2eec_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo.\n",
        "# 'optimizer=\"adam\"': El algoritmo que ajustará los pesos de las capas nuevas.\n",
        "# 'loss=\"binary_crossentropy\"': La función que mide qué tan bien lo está haciendo el modelo (para 2 clases).\n",
        "# 'metrics=[\"accuracy\"]': La métrica que queremos ver durante el entrenamiento (qué tan preciso es).\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Modelo compilado y listo para entrenar.\")"
      ],
      "metadata": {
        "id": "l5y7v5rhR1-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo.\n",
        "# 'train_ds': Nuestros datos de entrenamiento.\n",
        "# 'epochs=5': El número de veces que el modelo verá todo el dataset.\n",
        "# ¡Experimenten con el número de epochs!\n",
        "history = model.fit(train_ds, epochs=5)\n",
        "\n",
        "print(\"\\nEntrenamiento finalizado.\")"
      ],
      "metadata": {
        "id": "4rkX5N2_R41p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluación del Modelo"
      ],
      "metadata": {
        "id": "iq8BJb8CeqDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de una imagen de prueba (pueden cambiarla por una propia que suban a Colab)\n",
        "# Ejemplo: una URL de una imagen de gato o perro que encuentren online\n",
        "img_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg/1200px-Cat_August_2010-4.jpg\" # URL de un gato\n",
        "# img_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Canis_lupus_familiaris_%28dog%29.jpg/1200px-Canis_lupus_familiaris_%28dog%29.jpg\" # URL de un perro\n",
        "\n",
        "# Descargamos la imagen (si es una URL) o la cargamos localmente\n",
        "try:\n",
        "    img_path = tf.keras.utils.get_file('test_image.jpg', origin=img_url)\n",
        "except Exception:\n",
        "    print(\"No se pudo descargar la imagen, asegúrate que la URL es correcta.\")\n",
        "    # O si ya la subieron manualmente a Colab, usen su ruta:\n",
        "    # img_path = '/content/tu_imagen_test.jpg' # Ajusta esta ruta\n",
        "\n",
        "# Cargamos la imagen y la redimensionamos al tamaño esperado por el modelo\n",
        "img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) # Añadimos una dimensión extra para el batch\n",
        "img_array /= 255.0 # Normalizamos los valores de píxeles (0-1)\n",
        "\n",
        "# Realizamos la predicción\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Mostramos la imagen y la predicción\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "\n",
        "class_names = train_ds.class_names # Las clases que encontró tu dataset (ej. ['cats', 'dogs'])\n",
        "\n",
        "# Interpretamos la predicción\n",
        "# Si tienes 2 clases y sigmoid, la salida es un valor entre 0 y 1.\n",
        "# Si es >0.5 es la clase 1, si es <0.5 es la clase 0.\n",
        "predicted_class_index = (predictions[0] > 0.5).astype(int)[0]\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "confidence = predictions[0][0] if predicted_class_index == 1 else (1 - predictions[0][0])\n",
        "\n",
        "plt.title(f\"Predicción: {predicted_class_name} (Confianza: {confidence:.2f})\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Predicción numérica (es un valor entre 0 y 1 para la primera clase): {predictions[0]}\")\n",
        "print(f\"Clases del dataset: {class_names}\")"
      ],
      "metadata": {
        "id": "9XlJ4_v0R8YL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
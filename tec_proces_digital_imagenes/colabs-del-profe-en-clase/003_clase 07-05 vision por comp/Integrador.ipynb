{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalar la versión CORRECTA de OpenCV y luego importar\n",
        "\n",
        "# Desinstalar primero para evitar conflictos (el -y evita la pregunta de confirmación)\n",
        "!pip uninstall opencv-python -y\n",
        "!pip uninstall opencv-contrib-python -y # Asegurarse de quitar ambas si existen\n",
        "\n",
        "# Instalar la versión que incluye los módulos contrib\n",
        "!pip install opencv-contrib-python\n",
        "\n",
        "# --- IMPORTANTE ---\n",
        "# Después de ejecutar esta celda, DEBES REINICIAR EL ENTORNO DE EJECUCIÓN.\n",
        "# En Colab: Ve a \"Entorno de ejecución\" -> \"Reiniciar entorno de ejecución...\"\n",
        "# Luego, vuelve a ejecutar todas las celdas desde el principio.\n",
        "# ------------------"
      ],
      "metadata": {
        "id": "Fv2KWgCbAE_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio Integrador: Detección de Rostros y Puntos Faciales Clave (Landmarks)\n",
        "\n",
        "**Objetivo:** En esta práctica integradora, aplicaremos y conectaremos dos técnicas importantes de Visión por Computadora que hemos visto:\n",
        "\n",
        "1.  **Detección de Rostros:** Utilizaremos el método de Haar Cascades para encontrar la ubicación de múltiples caras dentro de una imagen.\n",
        "2.  **Detección de Landmarks Faciales:** Una vez localizadas las caras, aplicaremos un modelo más avanzado (LBF) para identificar 68 puntos clave específicos en cada rostro (ojos, cejas, nariz, boca, mandíbula).\n",
        "\n",
        "**Contexto:** Estas técnicas son fundamentales en muchas aplicaciones, desde filtros de redes sociales y sistemas de reconocimiento facial hasta análisis de expresiones o detección de somnolencia en conductores.\n",
        "\n",
        "**Imagen de Trabajo:** Usaremos una icónica imagen de la película argentina \"Nueve Reinas\".\n",
        "\n",
        "**¡Manos a la obra!**"
      ],
      "metadata": {
        "id": "Gqb1BChO-KlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 0: Configuración del Entorno\n",
        "\n",
        "Antes de comenzar, necesitamos asegurarnos de tener las librerías adecuadas y descargar los archivos necesarios (imagen, modelos pre-entrenados).\n",
        "\n",
        "### 0.1 Instalación e Importación de Librerías\n",
        "\n",
        "*   **`opencv-python` (`cv2`):** Librería esencial para visión por computadora.\n",
        "*   **`opencv-contrib-python`:** Contiene módulos extra de OpenCV, incluyendo `cv2.face` que usaremos para los landmarks. A menudo, instalar este paquete reemplaza o incluye `opencv-python`.\n",
        "*   **`matplotlib.pyplot` (`plt`):** Para visualizar imágenes dentro del cuaderno.\n",
        "*   **`numpy` (`np`):** Para manejo eficiente de arrays (las imágenes son arrays)."
      ],
      "metadata": {
        "id": "VThNRqVl-WFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar librerías (si es necesario) y luego importar\n",
        "# Usamos %%capture para ocultar la salida detallada de la instalación.\n",
        "#%%capture\n",
        "#!pip uninstall opencv-python -y # Desinstalar versión base si existe\n",
        "#!pip install matplotlib opencv-contrib-python # Instalar versión con módulos extra\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Librerías importadas.\")"
      ],
      "metadata": {
        "id": "rHnhyMag-bF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2 Descarga de Recursos\n",
        "\n",
        "Descargaremos:\n",
        "\n",
        "1.  **Imagen:** `9reinas.jpg`.\n",
        "2.  **Clasificador Haar:** `haarcascade_frontalface_default.xml`. Lo descargaremos directamente del repositorio oficial de OpenCV en GitHub. Este archivo contiene los patrones Haar pre-calculados para detectar rostros frontales.\n",
        "3.  **Modelo de Landmarks LBF:** `lbfmodel.yaml`. Este es un modelo pre-entrenado específico para el algoritmo LBF (Local Binary Features) de detección de landmarks. (Usaremos el enlace del cuaderno original, ya que es una fuente común para este archivo específico). *Nota: Este archivo es grande (~70Mb) y puede tardar un poco.*"
      ],
      "metadata": {
        "id": "AcS9CWAj-gtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar archivos necesarios\n",
        "\n",
        "# Descargar clasificador Haar desde el repositorio oficial de OpenCV\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml -O haarcascade_frontalface_default.xml\n",
        "print(\"Clasificador Haar descargado.\")\n",
        "\n",
        "# Descargar modelo de landmarks LBF (puede tardar)\n",
        "# Usamos %%capture para ocultar la salida si es muy larga\n",
        "#%%capture\n",
        "!wget https://github.com/kurnianggoro/GSOC2017/raw/master/data/lbfmodel.yaml -O lbfmodel.yaml\n",
        "print(\"Modelo LBF para landmarks descargado.\")\n",
        "print(\"¡Recursos listos!\")"
      ],
      "metadata": {
        "id": "-LMKGZiX-oOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.3 Carga Inicial de la Imagen\n",
        "\n",
        "Cargamos la imagen descargada usando `cv2.imread`."
      ],
      "metadata": {
        "id": "KNjo9SvQ-7OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar la imagen original\n",
        "img = cv2.imread(\"../imgs/9reinas.jpg\")\n",
        "\n",
        "if img is None:\n",
        "  print(\"Error al cargar la imagen '../imgs/9reinas.jpg'. Verifica la ruta.\")\n",
        "else:\n",
        "  print(\"Imagen original cargada (formato BGR). Dimensiones:\", img.shape)"
      ],
      "metadata": {
        "id": "doP2YZUf-6Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 1: Detección de Rostros con Haar Cascades\n",
        "\n",
        "**Concepto:** Las Haar Cascades son un método rápido basado en características visuales simples (diferencias de intensidad en patrones tipo Haar) para detectar objetos, en este caso, rostros. El clasificador (`.xml`) contiene una \"cascada\" de filtros: la imagen pasa por filtros cada vez más específicos, y si falla en uno temprano, se descarta rápidamente, haciendo el proceso eficiente. Funciona mejor en escala de grises.\n",
        "\n",
        "### 1.1 **Ejercicio 1:** Convertir la Imagen a RGB\n",
        "\n",
        "OpenCV carga en BGR. Para mostrar con Matplotlib, la convertimos a RGB."
      ],
      "metadata": {
        "id": "1D6DNVnF_DR8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQ0BGPkD_G3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 **Ejercicio 2:** Convertir la Imagen a Escala de Grises\n",
        "\n",
        "El detector Haar necesita la imagen en escala de grises."
      ],
      "metadata": {
        "id": "5PPu6y_9_NJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4W1CBIiF_Nvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 **Ejercicio 3:** Cargar Clasificador y Detectar Rostros\n",
        "\n",
        "Cargamos el archivo `.xml` y usamos el método `detectMultiScale` sobre la imagen gris. Este método busca caras en diferentes tamaños y devuelve una lista de rectángulos `(x, y, ancho, alto)` por cada cara encontrada."
      ],
      "metadata": {
        "id": "-j0uiMTq_UuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5aGlnpe_UOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 **Ejercicio 4:** Dibujar Bounding Boxes y Nombres\n",
        "\n",
        "Visualizamos los resultados dibujando rectángulos y nombres sobre la imagen RGB.\n",
        "\n",
        "**Tarea:** Dibuja la bounding box de Darín en rojo y la de Pauls en verde. Añade sus nombres encima.\n",
        "*Asumiremos que `faces[0]` es Pauls y `faces[1]` es Darín según el orden de detección típico (puede variar).*"
      ],
      "metadata": {
        "id": "0Tz8WnuC_bqT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXZg_pgk_cRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 2: Detección de Landmarks Faciales con LBF\n",
        "\n",
        "**Concepto:** Una vez ubicada una cara (con su bounding box), podemos usar un detector de landmarks para encontrar puntos precisos en ella. El método LBF (Local Binary Features) usa un modelo (`lbfmodel.yaml`) entrenado para localizar 68 puntos estándar en el rostro. Necesita la imagen en escala de grises y las bounding boxes como entrada.\n",
        "\n",
        "### 2.1 Cargar Modelo y Detectar Landmarks"
      ],
      "metadata": {
        "id": "cv_SmYOB_kBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el detector de landmarks y aplicarlo\n",
        "\n",
        "if img_gray is not None and len(faces) > 0:\n",
        "  # Creamos el detector\n",
        "  landmark_detector = cv2.face.createFacemarkLBF()\n",
        "  # Cargamos el modelo\n",
        "  try:\n",
        "    landmark_detector.loadModel(\"lbfmodel.yaml\")\n",
        "    print(\"Modelo LBF cargado.\")\n",
        "\n",
        "    # Aplicamos el detector ('fit')\n",
        "    # Recibe la imagen GRIS y las bounding boxes 'faces'\n",
        "    ok, all_landmarks = landmark_detector.fit(img_gray, faces)\n",
        "\n",
        "    if ok:\n",
        "      print(f\"Se detectaron landmarks para {len(all_landmarks)} rostro(s).\")\n",
        "      # all_landmarks es una lista, cada elemento es un array de landmarks para una cara\n",
        "    else:\n",
        "      print(\"Error durante la detección de landmarks con .fit()\")\n",
        "      all_landmarks = None\n",
        "\n",
        "  except cv2.error as e:\n",
        "    print(f\"Error cargando o usando el modelo LBF: {e}\")\n",
        "    print(\"Asegúrate que 'lbfmodel.yaml' se descargó correctamente.\")\n",
        "    all_landmarks = None\n",
        "else:\n",
        "  print(\"Se requiere la imagen gris y las caras detectadas ('faces').\")\n",
        "  all_landmarks = None"
      ],
      "metadata": {
        "id": "bBclHHC0_k7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Procesar y Visualizar Landmarks (Pauls)\n",
        "\n",
        "Los landmarks vienen en un formato específico (array 3D, tipo float). Los procesamos para obtener un array 2D de enteros `(x, y)` para cada uno de los 68 puntos del primer rostro (Pauls) y los dibujamos."
      ],
      "metadata": {
        "id": "gRIUNvDQBBUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesar y dibujar landmarks de Pauls\n",
        "\n",
        "if all_landmarks is not None and len(all_landmarks) >= 1:\n",
        "  # Landmarks del primer rostro (indice 0)\n",
        "  landmarks_pauls = all_landmarks[0]\n",
        "  # Quitar dimensión extra y convertir a enteros\n",
        "  landmarks_pauls = landmarks_pauls[0].astype(int)\n",
        "  print(\"Landmarks Pauls procesados. Forma:\", landmarks_pauls.shape) # Debe ser (68, 2)\n",
        "\n",
        "  # Dibujar sobre la imagen 'img_rgb' (que ya tiene boxes/nombres)\n",
        "  print(\"\\nDibujando landmarks de Pauls (verde):\")\n",
        "  for x, y in landmarks_pauls:\n",
        "      cv2.circle(img_rgb, (x, y), 0, (0, 255, 0), 1) # Radio 0, grosor 1 para punto pequeño\n",
        "  plt.imshow(img_rgb)\n",
        "  plt.title(\"Rostros + Landmarks Pauls\")\n",
        "\n",
        "  # Mostrar zoom\n",
        "  print(\"\\nZoom en Pauls:\")\n",
        "  plt.figure()\n",
        "  plt.imshow(img_rgb[80:140, 250:330])\n",
        "  plt.title(\"Zoom Landmarks Pauls\")\n",
        "\n",
        "else:\n",
        "  print(\"No hay landmarks disponibles para procesar.\")"
      ],
      "metadata": {
        "id": "aLk4fyv9BA_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 **Ejercicio 5:** Procesar y Dibujar Landmarks (Darín)\n",
        "\n",
        "**Tarea:** Haz lo mismo que en la celda anterior pero para el segundo rostro (Darín, índice 1) y dibuja sus landmarks en rojo sobre la *misma* imagen `img_rgb`."
      ],
      "metadata": {
        "id": "Wsl7YW3FBJXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solución Ejercicio 5 (Procesar y dibujar landmarks Darín)\n",
        "\n",
        "if all_landmarks is not None and len(all_landmarks) >= 2:\n",
        "  # Procesar landmarks Darín (indice 1)\n",
        "  landmarks_darin = all_landmarks[1]\n",
        "  landmarks_darin = landmarks_darin[0].astype(int)\n",
        "  print(\"Landmarks Darín procesados. Forma:\", landmarks_darin.shape)\n",
        "\n",
        "  # Dibujar sobre la imagen 'img_rgb' existente\n",
        "  print(\"\\nDibujando landmarks de Darín (rojo):\")\n",
        "  for x, y in landmarks_darin:\n",
        "      cv2.circle(img_rgb, (x, y), 0, (255, 0, 0), 1)\n",
        "  plt.imshow(img_rgb)\n",
        "  plt.title(\"Rostros + Ambos Landmarks\")\n",
        "\n",
        "  # Mostrar zoom\n",
        "  print(\"\\nZoom en Darín:\")\n",
        "  plt.figure()\n",
        "  plt.imshow(img_rgb[70:150, 130:190])\n",
        "  plt.title(\"Zoom Landmarks Darín\")\n",
        "\n",
        "elif all_landmarks is None:\n",
        "  print(\"No hay landmarks disponibles.\")\n",
        "elif len(all_landmarks) < 2:\n",
        "  print(\"Solo se detectó 1 rostro, no se pueden procesar landmarks para Darín.\")"
      ],
      "metadata": {
        "id": "CNXLOIMOBI31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 3: Selección y Aplicación de Landmarks\n",
        "\n",
        "Conociendo el índice de cada landmark (ver imagen de la malla), podemos seleccionar y usar solo los puntos que nos interesan para tareas específicas.\n",
        "\n",
        "### 3.1 **Ejercicio 6:** Dibujar Ojos y Boca (Pauls)\n",
        "\n",
        "**Tarea:**\n",
        "1.  Define listas con los índices correspondientes a los ojos y la boca.\n",
        "2.  Crea una **copia limpia** de la imagen RGB original (`img_con_partes = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)`).\n",
        "3.  Itera sobre `landmarks_pauls`.\n",
        "4.  Dibuja solo los puntos de ojos y boca sobre `img_con_partes` usando colores distintos (Magenta, Azul, Cian).\n",
        "5.  Muestra un zoom en Pauls de la imagen resultante."
      ],
      "metadata": {
        "id": "loq0ypU2BQ7l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3KhOW5iBbOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sección 4: Conclusión y Próximos Pasos\n",
        "\n",
        "En este laboratorio, hemos integrado la detección de rostros con la localización de landmarks faciales usando OpenCV. Vimos cómo preparar la imagen, aplicar los detectores y visualizar los resultados, incluyendo la selección de puntos específicos.\n",
        "\n",
        "Estos landmarks son bloques de construcción para aplicaciones más avanzadas como:\n",
        "*   **Detección de Somnolencia/Bostezos:** Calculando Eye Aspect Ratio (EAR) y Mouth Aspect Ratio (MAR).\n",
        "*   **Análisis de Expresiones Faciales.**\n",
        "*   **Realidad Aumentada.**\n",
        "\n",
        "**Ideas para continuar:**\n",
        "*   Investiga y calcula EAR y MAR para los rostros detectados.\n",
        "*   Aplica este flujo de trabajo a otras imágenes o a los fotogramas de un video."
      ],
      "metadata": {
        "id": "fzB_DM5UBh7z"
      }
    }
  ]
}
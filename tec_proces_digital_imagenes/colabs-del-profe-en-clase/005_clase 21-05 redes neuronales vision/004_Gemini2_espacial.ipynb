{"cells":[{"cell_type":"markdown","id":"5fe98c97","metadata":{"id":"5fe98c97"},"source":["# Comprensión espacial 2D con Gemini 2.0\n","\n","Cuaderno traducido al español por Matias Barreto para enseñar comprensión espacial 2D con Gemini 2.0."]},{"cell_type":"markdown","id":"82017914","metadata":{"id":"82017914"},"source":["## 1. Instalar el SDK\n","\n","Instalá el paquete `google-genai` usando pip para acceder a la API de Gemini."]},{"cell_type":"code","execution_count":null,"id":"82e2f094","metadata":{"id":"82e2f094"},"outputs":[],"source":["%pip install -U -q google-genai"]},{"cell_type":"markdown","id":"7ae2c85a","metadata":{"id":"7ae2c85a"},"source":["## 2. Configurar la clave de API\n","\n","Configurá tu clave de API de Google almacenada en un secreto de Colab o como variable de entorno. Si no tenés una clave, consultá la documentación oficial para obtenerla."]},{"cell_type":"code","execution_count":null,"id":"dcde839b","metadata":{"id":"dcde839b"},"outputs":[],"source":["from google.colab import userdata\n","import os\n","\n","GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"]},{"cell_type":"markdown","id":"81e7bd1b","metadata":{"id":"81e7bd1b"},"source":["## 3. Inicializar el cliente del SDK\n","\n","Inicializá el cliente de Gemini con tu clave de API para poder hacer solicitudes al modelo."]},{"cell_type":"code","execution_count":null,"id":"7a28fe0d","metadata":{"id":"7a28fe0d"},"outputs":[],"source":["from google import genai\n","from google.genai import types\n","\n","cliente = genai.Client(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","id":"d7403f5f","metadata":{"id":"d7403f5f"},"source":["## 4. Seleccionar y configurar el modelo\n","\n","Elegí el modelo de Gemini que quieras usar y configurá el nombre según tus necesidades. Los modelos 2.5 suelen dar mejores resultados para segmentación y razonamiento avanzado."]},{"cell_type":"code","execution_count":null,"id":"4c88b6a9","metadata":{"id":"4c88b6a9"},"outputs":[],"source":["nombre_modelo = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}"]},{"cell_type":"markdown","id":"765e86da","metadata":{"id":"765e86da"},"source":["## 5. Definir instrucciones del sistema y configuración de seguridad\n","\n","Definí las instrucciones del sistema para el modelo y configurá los parámetros de seguridad para el contenido generado."]},{"cell_type":"code","execution_count":null,"id":"71c55504","metadata":{"id":"71c55504"},"outputs":[],"source":["instrucciones_sistema_bbox = \"\"\"\n","    Devolvé los bounding boxes como un array JSON con etiquetas. Nunca devuelvas máscaras ni código. Limitá a 25 objetos.\n","    Si un objeto aparece varias veces, nombralos según alguna característica única (color, tamaño, posición, etc.).\n","\"\"\"\n","config_seguridad = [\n","    types.SafetySetting(\n","        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n","        threshold=\"BLOCK_ONLY_HIGH\",\n","    ),\n","]"]},{"cell_type":"markdown","id":"31b5a92b","metadata":{"id":"31b5a92b"},"source":["## 6. Importar módulos necesarios\n","\n","Importá todas las librerías y módulos requeridos, como PIL, requests, io, json, numpy, etc."]},{"cell_type":"code","execution_count":null,"id":"e723b240","metadata":{"id":"e723b240"},"outputs":[],"source":["import google.generativeai as genai\n","from PIL import Image\n","\n","import io\n","import os\n","import requests\n","from io import BytesIO\n","import json\n","import random\n","import numpy as np\n","import base64\n","import dataclasses\n","from PIL import ImageDraw, ImageFont, ImageColor"]},{"cell_type":"markdown","id":"bfb1e0f2","metadata":{"id":"bfb1e0f2"},"source":["## 7. Funciones utilitarias para procesamiento y visualización\n","\n","Definí funciones para parsear la salida JSON, dibujar bounding boxes y segmentaciones sobre las imágenes."]},{"cell_type":"code","execution_count":null,"id":"60fdbcbb","metadata":{"id":"60fdbcbb"},"outputs":[],"source":["# Parsear la salida JSON del modelo\n","def parsear_json(salida_json: str):\n","    lineas = salida_json.splitlines()\n","    for i, linea in enumerate(lineas):\n","        if linea == \"```json\":\n","            salida_json = \"\\n\".join(lineas[i+1:])\n","            salida_json = salida_json.split(\"```\")[0]\n","            break\n","    return salida_json\n","\n","# Instalar fuente Noto para mostrar caracteres japoneses\n","!apt-get install fonts-noto-cjk -y\n","\n","colores_adicionales = [nombre for (nombre, _) in ImageColor.colormap.items()]\n","\n","def dibujar_bounding_boxes(imagen, bounding_boxes):\n","    \"\"\"\n","    Dibuja los bounding boxes sobre una imagen usando PIL y diferentes colores.\n","    \"\"\"\n","    img = imagen\n","    ancho, alto = img.size\n","    draw = ImageDraw.Draw(img)\n","    colores = [\n","        'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown',\n","        'gray', 'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon',\n","        'teal', 'olive', 'coral', 'lavender', 'violet', 'gold', 'silver'\n","    ] + colores_adicionales\n","\n","    bounding_boxes = parsear_json(bounding_boxes)\n","    font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n","\n","    for i, bbox in enumerate(json.loads(bounding_boxes)):\n","        color = colores[i % len(colores)]\n","        y1 = int(bbox[\"box_2d\"][0]/1000 * alto)\n","        x1 = int(bbox[\"box_2d\"][1]/1000 * ancho)\n","        y2 = int(bbox[\"box_2d\"][2]/1000 * alto)\n","        x2 = int(bbox[\"box_2d\"][3]/1000 * ancho)\n","        if x1 > x2:\n","            x1, x2 = x2, x1\n","        if y1 > y2:\n","            y1, y2 = y2, y1\n","        draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=4)\n","        if \"label\" in bbox:\n","            draw.text((x1 + 8, y1 + 6), bbox[\"label\"], fill=color, font=font)\n","    img.show()\n","\n","@dataclasses.dataclass(frozen=True)\n","class MascaraSegmentacion:\n","    y0: int\n","    x0: int\n","    y1: int\n","    x1: int\n","    mascara: np.array\n","    etiqueta: str\n","\n","def parsear_segmentaciones(salida_predicha: str, img_alto: int, img_ancho: int):\n","    items = json.loads(parsear_json(salida_predicha))\n","    mascaras = []\n","    for item in items:\n","        abs_y0 = int(item[\"box_2d\"][0] / 1000 * img_alto)\n","        abs_x0 = int(item[\"box_2d\"][1] / 1000 * img_ancho)\n","        abs_y1 = int(item[\"box_2d\"][2] / 1000 * img_alto)\n","        abs_x1 = int(item[\"box_2d\"][3] / 1000 * img_ancho)\n","        if abs_y0 >= abs_y1 or abs_x0 >= abs_x1:\n","            print(\"Bounding box inválido\", item[\"box_2d\"])\n","            continue\n","        etiqueta = item[\"label\"]\n","        png_str = item[\"mask\"]\n","        if not png_str.startswith(\"data:image/png;base64,\"):\n","            print(\"Máscara inválida\")\n","            continue\n","        png_str = png_str.removeprefix(\"data:image/png;base64,\")\n","        png_str = base64.b64decode(png_str)\n","        mascara = Image.open(io.BytesIO(png_str))\n","        alto_bbox = abs_y1 - abs_y0\n","        ancho_bbox = abs_x1 - abs_x0\n","        if alto_bbox < 1 or ancho_bbox < 1:\n","            print(\"Bounding box inválido\")\n","            continue\n","        mascara = mascara.resize((ancho_bbox, alto_bbox), resample=Image.Resampling.BILINEAR)\n","        np_mascara = np.zeros((img_alto, img_ancho), dtype=np.uint8)\n","        np_mascara[abs_y0:abs_y1, abs_x0:abs_x1] = mascara\n","        mascaras.append(MascaraSegmentacion(abs_y0, abs_x0, abs_y1, abs_x1, np_mascara, etiqueta))\n","    return mascaras\n","\n","def superponer_mascara(img: Image, mascara: np.ndarray, color: str, alpha: float = 0.7) -> Image.Image:\n","    if not (0.0 <= alpha <= 1.0):\n","        raise ValueError(\"Alpha debe estar entre 0.0 y 1.0\")\n","    color_rgb = ImageColor.getrgb(color)\n","    img_rgba = img.convert(\"RGBA\")\n","    ancho, alto = img_rgba.size\n","    alpha_int = int(alpha * 255)\n","    color_rgba = color_rgb + (alpha_int,)\n","    capa_mascara = np.zeros((alto, ancho, 4), dtype=np.uint8)\n","    mascara_logica = mascara > 127\n","    capa_mascara[mascara_logica] = color_rgba\n","    capa_pil = Image.fromarray(capa_mascara, 'RGBA')\n","    resultado = Image.alpha_composite(img_rgba, capa_pil)\n","    return resultado\n","\n","def dibujar_segmentaciones(img: Image, mascaras: list):\n","    colores = [\n","        'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown',\n","        'gray', 'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon',\n","        'teal', 'olive', 'coral', 'lavender', 'violet', 'gold', 'silver'\n","    ] + colores_adicionales\n","    font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n","    for i, mascara in enumerate(mascaras):\n","        color = colores[i % len(colores)]\n","        img = superponer_mascara(img, mascara.mascara, color)\n","    draw = ImageDraw.Draw(img)\n","    for i, mascara in enumerate(mascaras):\n","        color = colores[i % len(colores)]\n","        draw.rectangle(((mascara.x0, mascara.y0), (mascara.x1, mascara.y1)), outline=color, width=4)\n","    for i, mascara in enumerate(mascaras):\n","        color = colores[i % len(colores)]\n","        if mascara.etiqueta != \"\":\n","            draw.text((mascara.x0 + 8, mascara.y0 - 20), mascara.etiqueta, fill=color, font=font)\n","    img.show()"]},{"cell_type":"markdown","id":"a956b42d","metadata":{"id":"a956b42d"},"source":["## 8. Descargar imágenes de ejemplo\n","\n","Descargá imágenes de ejemplo desde URLs públicas para usarlas en los ejercicios del cuaderno."]},{"cell_type":"code","execution_count":null,"id":"27db6cb2","metadata":{"id":"27db6cb2"},"outputs":[],"source":["!wget https://storage.googleapis.com/generativeai-downloads/images/socks.jpg -O Socks.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/vegetables.jpg -O Vegetables.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/Japanese_Bento.png -O Japanese_bento.png -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/Cupcakes.jpg -O Cupcakes.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/origamis.jpg -O Origamis.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/fruits.jpg -O Fruits.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/cat.jpg -O Cat.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/pumpkins.jpg -O Pumpkins.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/breakfast.jpg -O Breakfast.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/bookshelf.jpg -O Bookshelf.jpg -q\n","!wget https://storage.googleapis.com/generativeai-downloads/images/spill.jpg -O Spill.jpg -q"]},{"cell_type":"markdown","id":"b2d1f900","metadata":{"id":"b2d1f900"},"source":["## 9. Cargar y mostrar una imagen\n","\n","Cargá una imagen de ejemplo, redimensionala y mostrála para comenzar a trabajar sobre ella."]},{"cell_type":"code","execution_count":null,"id":"c55970f1","metadata":{"id":"c55970f1"},"outputs":[],"source":["imagen = \"Vegetables.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","\n","im = Image.open(imagen)\n","im.thumbnail([620, 620], Image.Resampling.LANCZOS)\n","im"]},{"cell_type":"markdown","id":"c59fba33","metadata":{"id":"c59fba33"},"source":["## 10. Detectar objetos y dibujar bounding boxes\n","\n","Enviá la imagen y un prompt al modelo para detectar objetos y visualizar los bounding boxes sobre la imagen."]},{"cell_type":"code","execution_count":null,"id":"4f81050a","metadata":{"id":"4f81050a"},"outputs":[],"source":["prompt = \"Detectá los bounding boxes 2D de las verduras (usá 'label' como descripción del topping)\"  # @param {type:\"string\"}\n","\n","im = Image.open(BytesIO(open(imagen, \"rb\").read()))\n","im.thumbnail([1024, 1024], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        system_instruction=instrucciones_sistema_bbox,\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","print(respuesta.text)"]},{"cell_type":"code","execution_count":null,"id":"af295f38","metadata":{"id":"af295f38"},"outputs":[],"source":["dibujar_bounding_boxes(im, respuesta.text)\n","im"]},{"cell_type":"markdown","id":"1c84bf38","metadata":{"id":"1c84bf38"},"source":["## 11. Buscar objetos específicos en una imagen\n","\n","Ejecutá prompts personalizados para buscar y resaltar objetos específicos dentro de una imagen."]},{"cell_type":"code","execution_count":null,"id":"0bd0a45e","metadata":{"id":"0bd0a45e"},"outputs":[],"source":["imagen = \"Socks.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","prompt = \"Mostrame las posiciones de las medias con carita\"  # @param [\"Detectá todas las medias arcoíris\", \"Encontrá todas las medias y etiquetalas con emojis\", \"Mostrame las posiciones de las medias con carita\", \"Encontrá la media que hace juego con la de arriba\"] {\"allow-input\":true}\n","\n","im = Image.open(imagen)\n","im.thumbnail([640, 640], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        system_instruction=instrucciones_sistema_bbox,\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","print(respuesta.text)\n","dibujar_bounding_boxes(im, respuesta.text)\n","im"]},{"cell_type":"markdown","id":"0eb13d27","metadata":{"id":"0eb13d27"},"source":["## 12. Ejemplo de razonamiento multilingüe\n","\n","Pedile al modelo que etiquete objetos en la imagen usando japonés y traducción al inglés, demostrando capacidades multilingües."]},{"cell_type":"code","execution_count":null,"id":"80e42789","metadata":{"id":"80e42789"},"outputs":[],"source":["imagen = \"Japanese_bento.png\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","prompt = \"Detectá la comida y etiquetala con caracteres japoneses y traducción al inglés.\"  # @param [\"Detectá la comida y etiquetala con caracteres japoneses y traducción al inglés.\", \"Mostrame los platos veganos\", \"Explicá qué son esos platos en 5 palabras\", \"Encontrá los platos con alérgenos y etiquetalos\"] {\"allow-input\":true}\n","\n","im = Image.open(imagen)\n","im.thumbnail([640, 640], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        system_instruction=instrucciones_sistema_bbox,\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","dibujar_bounding_boxes(im, respuesta.text)\n","im"]},{"cell_type":"markdown","id":"7fba7325","metadata":{"id":"7fba7325"},"source":["## 13. Ejemplo de razonamiento espacial avanzado\n","\n","Usá prompts que requieran razonamiento espacial, como encontrar sombras o dar consejos basados en la imagen."]},{"cell_type":"code","execution_count":null,"id":"542e7ddf","metadata":{"id":"542e7ddf"},"outputs":[],"source":["imagen = \"Origamis.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","prompt = \"Dibujá un cuadrado alrededor de la sombra del zorro\"  # @param [\"Encontrá los dos animales de origami.\", \"¿Dónde están las sombras de los origamis?\", \"Dibujá un cuadrado alrededor de la sombra del zorro\"] {\"allow-input\":true}\n","\n","im = Image.open(imagen)\n","im.thumbnail([640, 640], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        system_instruction=instrucciones_sistema_bbox,\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","dibujar_bounding_boxes(im, respuesta.text)\n","im"]},{"cell_type":"code","execution_count":null,"id":"3d9a779e","metadata":{"id":"3d9a779e"},"outputs":[],"source":["imagen = \"Spill.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","prompt = \"Decime cómo limpiar mi mesa con una explicación como etiqueta. No solo etiquetes los objetos.\"  # @param [\"Mostrame dónde se derramó mi café.\", \"Decime cómo limpiar mi mesa con una explicación como etiqueta. No solo etiquetes los objetos.\", \"Dibujá un cuadrado alrededor de la sombra del zorro\"] {\"allow-input\":true}\n","\n","im = Image.open(imagen)\n","im.thumbnail([640, 640], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        system_instruction=instrucciones_sistema_bbox,\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","dibujar_bounding_boxes(im, respuesta.text)\n","im"]},{"cell_type":"markdown","id":"9512fc04","metadata":{"id":"9512fc04"},"source":["## 14. Segmentación de imágenes y visualización de máscaras\n","\n","Pedile al modelo máscaras de segmentación, decodificalas y superponelas sobre la imagen para una visualización avanzada."]},{"cell_type":"code","execution_count":null,"id":"1d9ca6b9","metadata":{"id":"1d9ca6b9"},"outputs":[],"source":["imagen = \"Cupcakes.jpg\" # @param [\"Socks.jpg\",\"Vegetables.jpg\",\"Japanese_bento.png\",\"Cupcakes.jpg\",\"Origamis.jpg\",\"Fruits.jpg\",\"Cat.jpg\",\"Pumpkins.jpg\",\"Breakfast.jpg\",\"Bookshelf.jpg\", \"Spill.jpg\"] {\"allow-input\":true}\n","prompt = \"Dame las máscaras de segmentación para los objetos pequeños de metal, madera y vidrio (ignorá la mesa). Devolvé una lista JSON donde cada entrada tenga el bounding box en 'box_2d', la máscara en 'mask' y la etiqueta en 'label'. Usá etiquetas descriptivas.\"  # @param {type:\"string\"}\n","\n","im = Image.open(BytesIO(open(imagen, \"rb\").read()))\n","im.thumbnail([1024, 1024], Image.Resampling.LANCZOS)\n","\n","respuesta = cliente.models.generate_content(\n","    model=nombre_modelo,\n","    contents=[prompt, im],\n","    config=types.GenerateContentConfig(\n","        temperature=0.5,\n","        safety_settings=config_seguridad,\n","    )\n",")\n","\n","print(respuesta.text)\n","mascaras = parsear_segmentaciones(respuesta.text, img_alto=im.size[1], img_ancho=im.size[0])\n","dibujar_segmentaciones(im, mascaras)"]},{"cell_type":"markdown","id":"6e801533","metadata":{"id":"6e801533"},"source":["## 15. Capacidades preliminares: punteo y cajas 3D\n","\n","Las capacidades de punteo (pointing) y cajas 3D son experimentales en los modelos Gemini. Si te interesa explorar estas funciones avanzadas, podés consultar el siguiente cuaderno de ejemplo:\n","\n","[Ejemplo de comprensión espacial 3D](../examples/Spatial_understanding_3d.ipynb)\n","\n","<a href=\"../examples/Spatial_understanding_3d.ipynb\"><img src=\"https://storage.googleapis.com/generativeai-downloads/images/box_3d.png\" height=\"400\"/></a>\n"]},{"cell_type":"markdown","id":"b9350701","metadata":{"id":"b9350701"},"source":["## 16. ¿Qué sigue?\n","\n","Para ver un ejemplo más completo y de punta a punta, podés revisar el código del [ejemplo de AI Studio](https://aistudio.google.com/starter-apps/spatial) disponible en [Github](https://github.com/google-gemini/starter-applets/tree/main/spatial).\n","\n","También vas a encontrar muchos otros ejemplos de las capacidades de Gemini 2.0 en el [cookbook oficial](https://github.com/google-gemini/cookbook/tree/main/gemini-2/), incluyendo:\n","\n","- [API en vivo](./Get_started_LiveAPI.ipynb)\n","- [Comprensión de video](./Video_understanding.ipynb)\n","- [Ejemplo de marketing de mochila a propulsión](../examples/Market_a_Jet_Backpack.ipynb)\n","- [Adiviná la forma](../examples/Guess_the_shape.ipynb)\n","\n","Y, por supuesto, el ejemplo de [punteo y cajas 3D](../examples/Spatial_understanding_3d.ipynb) mencionado antes."]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
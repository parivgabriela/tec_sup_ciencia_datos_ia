{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "## Visualización de Filtros y Activaciones en Redes Neuronales Convolucionales (CNNs)\n",
        "\n",
        "Este cuaderno tiene como objetivo principal desmitificar las **Redes Neuronales Convolucionales (CNNs)**, mostrando cómo sus capas internas \"ven\" y \"procesan\" las imágenes. A menudo, las CNNs pueden parecer \"cajas negras\", pero al visualizar sus **filtros (kernels)** y las **activaciones (mapas de características)**, podemos obtener una comprensión intuitiva de cómo aprenden a detectar patrones.\n",
        "\n",
        "En este laboratorio, construiremos y entrenaremos una CNN simple en el dataset MNIST (dígitos escritos a mano) y luego exploraremos:\n",
        "1.  **Los filtros aprendidos** en las capas convolucionales.\n",
        "2.  **Los mapas de características (activaciones)** que se generan a medida que una imagen pasa por la red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_data_loading"
      },
      "source": [
        "### 1. Configuración Inicial y Carga de Datos\n",
        "\n",
        "Comenzaremos importando las librerías necesarias y cargando el popular dataset MNIST. MNIST consta de 60,000 imágenes de entrenamiento y 10,000 imágenes de prueba de dígitos escritos a mano (0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Importamos TensorFlow, la API de Keras (layers y models) y Matplotlib.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models # 'layers' para definir capas, 'models' para Sequential y Model\n",
        "import matplotlib.pyplot as plt # Para todas las visualizaciones\n",
        "import numpy as np # Para operaciones con arrays numéricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_mnist"
      },
      "outputs": [],
      "source": [
        "# Cargamos el dataset MNIST directamente desde Keras.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocesamiento de las imágenes:\n",
        "# 1. Expandimos las dimensiones: MNIST tiene imágenes de 28x28. Las CNNs esperan (alto, ancho, canales).\n",
        "#    Para imágenes en escala de grises, el canal es 1. Usamos 'None' para añadir esta dimensión.\n",
        "x_train = x_train[..., None] / 255.0 # Añade un eje al final y normaliza a [0, 1]\n",
        "x_test  = x_test[..., None]  / 255.0  # Misma operación para el conjunto de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize_sample_data"
      },
      "source": [
        "### 1.1. Visualizar una Muestra de Datos\n",
        "\n",
        "Es útil ver cómo lucen las imágenes después del preprocesamiento, antes de pasarlas a la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_single_image"
      },
      "outputs": [],
      "source": [
        "# Mostramos una imagen de ejemplo del conjunto de entrenamiento.\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(x_train[0, :, :, 0], cmap='gray') # Muestra la primera imagen (28x28, 1 canal).\n",
        "plt.title(f\"Etiqueta: {y_train[0]}\")\n",
        "plt.axis('off') # Oculta los ejes para una visualización limpia.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "build_train_cnn"
      },
      "source": [
        "### 2. Construcción y Entrenamiento de una CNN Simple\n",
        "\n",
        "Construiremos una CNN sencilla con pocas capas para facilitar la visualización. Los componentes clave son:\n",
        "\n",
        "-   **`Conv2D` (Capa Convolucional):** Aplica un conjunto de filtros pequeños a la imagen de entrada, detectando características como bordes, texturas o patrones simples. Cada filtro genera un \"mapa de características\" o \"mapa de activación\".\n",
        "-   **`MaxPooling2D` (Capa de Agrupación Máxima):** Reduce la dimensionalidad de los mapas de características, tomando el valor máximo dentro de pequeñas ventanas. Esto ayuda a hacer la red más robusta a pequeñas traslaciones y a reducir el número de parámetros.\n",
        "-   **`ReLU` (Rectified Linear Unit):** Una función de activación no lineal que introduce no linealidad en el modelo, permitiéndole aprender patrones más complejos. Simplemente convierte todos los valores negativos en cero.\n",
        "-   **`Flatten`:** Convierte los mapas de características 2D/3D en un vector 1D, preparando los datos para las capas densas (fully connected).\n",
        "-   **`Dense` (Capa Densa/Completamente Conectada):** Capas neuronales tradicionales donde cada neurona está conectada a todas las neuronas de la capa anterior. Realizan la clasificación final.\n",
        "-   **`Softmax`:** Función de activación en la capa de salida para problemas de clasificación multiclase. Convierte los logits (salidas en bruto) en probabilidades que suman 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_train_model"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo Sequential de Keras.\n",
        "model = models.Sequential([\n",
        "    # Primera capa convolucional:\n",
        "    # 16 filtros de tamaño 3x3.\n",
        "    # 'activation='relu'' aplica la función de activación ReLU.\n",
        "    # 'input_shape=(28,28,1)' especifica la forma de la entrada (28x28 píxeles, 1 canal para escala de grises).\n",
        "    layers.Conv2D(16, 3, activation='relu', input_shape=(28,28,1)),\n",
        "\n",
        "    # Capa de agrupación máxima: reduce la dimensionalidad espacial (por defecto, 2x2).\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # Segunda capa convolucional: 32 filtros de tamaño 3x3.\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "\n",
        "    # Aplanamos la salida para conectar con las capas densas.\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Capa densa de salida:\n",
        "    # 10 neuronas (una para cada dígito 0-9).\n",
        "    # 'activation='softmax'' para obtener probabilidades de clase.\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compilamos el modelo.\n",
        "# 'optimizer='adam'': Un optimizador popular y eficiente.\n",
        "# 'loss='sparse_categorical_crossentropy'': Función de pérdida para clasificación multiclase con etiquetas enteras.\n",
        "# 'metrics=['accuracy']': Métrica para monitorear el rendimiento.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenamos el modelo.\n",
        "# 'x_train', 'y_train': Datos de entrenamiento.\n",
        "# 'epochs=3': Número de veces que el modelo verá todo el conjunto de entrenamiento.\n",
        "# 'validation_split=0.1': 10% de los datos de entrenamiento se usan para validación durante el entrenamiento.\n",
        "print(\"\\nEntrenando el modelo...\")\n",
        "model.fit(x_train, y_train, epochs=3, validation_split=0.1)\n",
        "print(\"Entrenamiento completado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize_filters"
      },
      "source": [
        "### 3. Visualización de Filtros (Kernels)\n",
        "\n",
        "Los **filtros** (también llamados kernels) son matrices pequeñas de pesos que la red aprende para detectar características específicas en la imagen. Cada filtro se desliza sobre la imagen (o mapas de características anteriores) realizando una operación de convolución.\n",
        "\n",
        "Podemos inspeccionar los pesos de los filtros de la primera capa convolucional para ver qué tipo de patrones elementales han aprendido a reconocer (por ejemplo, bordes horizontales, verticales, diagonales, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_filters"
      },
      "outputs": [],
      "source": [
        "# Obtenemos los pesos (filtros y sesgos) de la primera capa (índice 0, que es Conv2D).\n",
        "# 'get_weights()' devuelve una lista de arrays NumPy: el primer array son los filtros, el segundo son los sesgos.\n",
        "filters, biases = model.layers[0].get_weights()\n",
        "\n",
        "# Configuramos una figura para mostrar los filtros.\n",
        "# Creamos una cuadrícula de 4x4 subplots (para 16 filtros).\n",
        "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "fig.suptitle('Filtros Aprendidos en la Primera Capa Convolucional') # Título general de la figura\n",
        "\n",
        "# Iteramos sobre cada subplot para mostrar un filtro.\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Mostramos los pesos del filtro. filters[:,:,0,i] selecciona el i-ésimo filtro.\n",
        "    # El '0' en la tercera dimensión es porque MNIST tiene un solo canal de entrada.\n",
        "    ax.imshow(filters[:, :, 0, i], cmap='gray') # 'gray' para ver los pesos del filtro en escala de grises.\n",
        "    ax.set_title(f'Filtro {i+1}') # Título para cada filtro\n",
        "    ax.axis('off') # Desactivamos los ejes para una visualización limpia.\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta el layout para que el título no se superponga\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretación de los filtros:\\n\")\n",
        "print(\"Observa los pequeños patrones que cada filtro ha aprendido a reconocer.\")\n",
        "print(\"Algunos pueden detectar bordes verticales, otros horizontales, diagonales o esquinas.\")\n",
        "print(\"Estos son los 'bloques de construcción' básicos que la CNN usa para comprender la imagen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize_activations"
      },
      "source": [
        "### 4. Visualización de Mapas de Características (Activaciones)\n",
        "\n",
        "Los **mapas de características (o activaciones)** son las salidas de una capa convolucional después de que los filtros han procesado la entrada. Representan qué características del input han sido detectadas por cada filtro en diferentes ubicaciones.\n",
        "\n",
        "A medida que una imagen pasa por capas más profundas, los mapas de características tienden a volverse más abstractos y complejos, detectando patrones de nivel superior a partir de las características más simples detectadas por las capas anteriores.\n",
        "\n",
        "Para visualizar esto, crearemos un nuevo modelo que nos permita obtener las salidas de capas intermedias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "get_activations"
      },
      "outputs": [],
      "source": [
        "# Creamos un modelo intermedio para obtener las salidas de las primeras dos capas.\n",
        "# 'model.layers[0].input' es la entrada a la primera capa de nuestra CNN.\n",
        "# 'layer.output for layer in model.layers[:2]' selecciona las salidas de las dos primeras capas (Conv2D y MaxPooling2D).\n",
        "activation_model = models.Model(inputs=model.layers[0].input, outputs=[layer.output for layer in model.layers[:2]])\n",
        "\n",
        "# Obtenemos las activaciones para una imagen de prueba.\n",
        "# Usamos la primera imagen de prueba (x_test[0]) y la reformamos a (1, 28, 28, 1) para que coincida con el batch_size.\n",
        "sample_image = x_test[0][np.newaxis, ..., np.newaxis] # Añade una dimensión para el batch y para el canal si falta\n",
        "sample_image = x_test[0:1] # Forma más simple y directa para obtener un batch de tamaño 1\n",
        "\n",
        "activations = activation_model.predict(sample_image)\n",
        "\n",
        "print(f\"Activaciones obtenidas para la imagen de prueba con etiqueta: {y_test[0]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plot_conv_activations"
      },
      "source": [
        "### 4.1. Activaciones de la Primera Capa Convolucional (Conv2D)\n",
        "\n",
        "Estos mapas de características muestran cómo cada filtro de la primera capa respondió a la imagen de entrada. Un área más brillante en el mapa indica que el filtro detectó la característica que buscaba en esa región de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_first_layer_activations"
      },
      "outputs": [],
      "source": [
        "first_layer_activation = activations[0]  # Activaciones de la primera capa (Conv2D)\n",
        "\n",
        "print(f\"Forma de las activaciones de la primera capa: {first_layer_activation.shape}\") # (batch_size, alto, ancho, num_filtros)\n",
        "num_filters_first_layer = first_layer_activation.shape[-1] # Número de filtros/canales en la salida\n",
        "\n",
        "# Determinamos el tamaño de la cuadrícula para la visualización (ej. 4x4 para los 16 filtros).\n",
        "grid_size = min(int(np.ceil(np.sqrt(num_filters_first_layer))), 4)\n",
        "fig1, axes1 = plt.subplots(grid_size, grid_size, figsize=(8, 8))\n",
        "fig1.suptitle(f'Activaciones de la Primera Capa Conv2D (Imagen: {y_test[0]})')\n",
        "\n",
        "for i, ax in enumerate(axes1.flat):\n",
        "    if i < num_filters_first_layer:\n",
        "        # Mostramos el mapa de activación para el i-ésimo filtro de la primera imagen del lote.\n",
        "        ax.imshow(first_layer_activation[0, :, :, i], cmap='viridis') # 'viridis' es un buen cmap para activaciones\n",
        "        ax.set_title(f'Filtro {i+1}')\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off') # Ocultar subplots no usados\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta el layout para hacer espacio para el título\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretación de las activaciones Conv2D:\\n\")\n",
        "print(\"Cada mapa de activación muestra dónde y con qué intensidad un filtro específico 'reaccionó' a la imagen de entrada.\")\n",
        "print(\"Observa cómo diferentes filtros resaltan diferentes características (bordes, curvas, etc.) en la imagen original.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plot_pool_activations"
      },
      "source": [
        "### 4.2. Activaciones de la Segunda Capa (MaxPooling2D)\n",
        "\n",
        "Después de la capa convolucional, la capa `MaxPooling2D` reduce la resolución de los mapas de características. Esto ayuda a mantener la información más relevante y a hacer la red más robusta a pequeñas variaciones en la posición de las características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_second_layer_activations"
      },
      "outputs": [],
      "source": [
        "second_layer_activation = activations[1] # Activaciones de la segunda capa (MaxPooling2D)\n",
        "\n",
        "print(f\"Forma de las activaciones de la segunda capa: {second_layer_activation.shape}\") # (batch_size, alto_reducido, ancho_reducido, num_filtros)\n",
        "num_filters_second_layer = second_layer_activation.shape[-1]\n",
        "\n",
        "# Determinamos el tamaño de la cuadrícula para la visualización.\n",
        "grid_size_pool = min(int(np.ceil(np.sqrt(num_filters_second_layer))), 4)\n",
        "fig2, axes2 = plt.subplots(grid_size_pool, grid_size_pool, figsize=(8, 8))\n",
        "fig2.suptitle(f'Activaciones de la Segunda Capa MaxPooling2D (Imagen: {y_test[0]})')\n",
        "\n",
        "for i, ax in enumerate(axes2.flat):\n",
        "    if i < num_filters_second_layer:\n",
        "        # Mostramos el mapa de activación post-pooling.\n",
        "        ax.imshow(second_layer_activation[0, :, :, i], cmap='viridis')\n",
        "        ax.set_title(f'Mapa {i+1}')\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off') # Ocultar subplots no usados\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Ajusta el layout para hacer espacio para el título\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretación de las activaciones MaxPooling2D:\\n\")\n",
        "print(\"Observa que estos mapas son de menor resolución que los anteriores.\")\n",
        "print(\"MaxPooling reduce la dimensionalidad espacial, conservando la información más prominente detectada por los filtros.\")\n",
        "print(\"Esto hace que la red sea más eficiente y más tolerante a pequeñas variaciones en la posición de las características.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_exercises"
      },
      "source": [
        "## Conclusión y Ejercicios Sugeridos\n",
        "\n",
        "Has completado un ejercicio práctico de visualización en CNNs. Ahora tienes una mejor comprensión de:\n",
        "\n",
        "-   Cómo los **filtros** en las capas convolucionales aprenden a detectar patrones básicos.\n",
        "-   Cómo las **activaciones (mapas de características)** representan la presencia de esos patrones en diferentes regiones de la imagen y cómo evolucionan a través de las capas.\n",
        "-   El papel de las capas de **pooling** en la reducción de dimensionalidad y la creación de representaciones más robustas.\n",
        "\n",
        "Esta visualización es una herramienta valiosa para depurar modelos, interpretar su comportamiento y desarrollar una intuición más profunda sobre cómo funcionan las CNNs.\n",
        "\n",
        "---\n",
        "**Ejercicios Sugeridos para Experimentar:**\n",
        "\n",
        "-   **Modificar la Arquitectura:**\n",
        "    -   Añade más capas `Conv2D` y `MaxPooling2D`. ¿Cómo cambian los filtros y las activaciones en capas más profundas?\n",
        "    -   Cambia el número de filtros en una capa (ej. 32 a 64). ¿Hay más variedad en los patrones aprendidos?\n",
        "    -   Experimenta con diferentes tamaños de kernel (ej. 5x5 en lugar de 3x3).\n",
        "-   **Entrenar por más épocas:** ¿Los filtros se vuelven más definidos o específicos con más entrenamiento?\n",
        "-   **Probar con diferentes imágenes de entrada:** Selecciona diferentes dígitos del conjunto de prueba (`x_test[i]`) y observa cómo varían los mapas de características. ¿Qué patrones se activan para un '0' vs. un '1'?\n",
        "-   **Visualizar capas más profundas:** Adapta el `activation_model` para extraer y visualizar las activaciones de la *segunda* capa `Conv2D` de tu modelo. ¿Son más abstractas que las de la primera capa?\n",
        "-   **Cambiar la función de activación:** ¿Qué sucede si usas `sigmoid` o `tanh` en lugar de `relu`? (Ten en cuenta que `relu` es más común y eficiente para CNNs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glossary"
      },
      "source": [
        "## Glosario de Términos\n",
        "\n",
        "-   **Red Neuronal Convolucional (CNN):** Un tipo de red neuronal artificial especializada en procesar datos con una topología de cuadrícula, como imágenes, a través de capas convolucionales y de pooling.\n",
        "-   **Filtro (Kernel):** Una pequeña matriz de pesos que se desliza sobre la imagen de entrada (o un mapa de características) para detectar patrones específicos. La red aprende los valores de estos pesos durante el entrenamiento.\n",
        "-   **Activación (Mapa de Características / Feature Map):** La salida de una capa convolucional después de que un filtro ha sido aplicado y la función de activación (ej. ReLU) ha sido ejecutada. Cada mapa de características representa la presencia de una característica específica a lo largo de la imagen.\n",
        "-   **Capa Convolucional (`Conv2D`):** La capa principal de una CNN. Realiza la operación de convolución utilizando filtros para extraer características locales de la entrada.\n",
        "-   **Capa de Agrupación Máxima (`MaxPooling2D`):** Una capa que reduce la dimensionalidad espacial (ancho y alto) de los mapas de características, seleccionando el valor máximo dentro de cada ventana de agrupamiento. Ayuda a reducir el número de parámetros y hacer el modelo más robusto.\n",
        "-   **Función de Activación (`ReLU`, `Softmax`):** Funciones no lineales que se aplican a la salida de las neuronas. `ReLU` (Rectified Linear Unit) es común en capas ocultas, mientras que `Softmax` se usa en la capa de salida para problemas de clasificación multiclase, produciendo probabilidades.\n",
        "-   **Capa Densa (Fully Connected Layer):** Una capa donde cada neurona está conectada a cada neurona de la capa anterior. En las CNNs, se utilizan típicamente al final para la clasificación.\n",
        "-   **Capa `Flatten`:** Convierte la entrada (usualmente de un tensor 2D o 3D, como los mapas de características) en un vector 1D, preparándola para ser conectada a una capa densa.\n",
        "-   **MNIST:** Un conjunto de datos de dígitos escritos a mano ampliamente utilizado para el aprendizaje automático, especialmente para introducir redes neuronales convolucionales.\n",
        "-   **Normalización:** El proceso de escalar los valores de los píxeles de una imagen (ej. de 0-255 a 0-1) para facilitar el entrenamiento del modelo y mejorar su rendimiento.\n",
        "-   **Época:** Un ciclo completo de entrenamiento, donde el modelo procesa todo el conjunto de datos de entrenamiento una vez.\n",
        "-   **Optimizador (`Adam`):** Un algoritmo utilizado para ajustar los pesos de la red neuronal durante el entrenamiento, con el objetivo de minimizar la función de pérdida. Adam es un optimizador adaptativo popular.\n",
        "-   **Función de Pérdida (`sparse_categorical_crossentropy`):** Una métrica que el modelo intenta minimizar durante el entrenamiento. Mide la diferencia entre las predicciones del modelo y las etiquetas reales. `sparse_categorical_crossentropy` es adecuada cuando las etiquetas de clase son números enteros."
      ]
    }
  ]
}